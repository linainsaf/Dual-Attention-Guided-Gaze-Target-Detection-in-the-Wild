{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-i INPUT_PATH] [-o OUTPUT_PATH]\n",
      "                             [-m MODEL_WEIGHTS] [-t MODEL_TYPE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/delphinedoutsas/Library/Jupyter/runtime/kernel-abcdc2ef-7614-491e-960e-058c225df969.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3333: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Compute depth maps for images in the input folder.\n",
    "\"\"\"\n",
    "import os\n",
    "import glob\n",
    "import utils\n",
    "import cv2\n",
    "import argparse\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from transforms import Resize, NormalizeImage, PrepareForNet\n",
    "\n",
    "def run(input_path, output_path, model_path, model_type=\"large\"):\n",
    "    \"\"\"Run MonoDepthNN to compute depth maps.\n",
    "\n",
    "    Args:\n",
    "        input_path (str): path to input folder\n",
    "        output_path (str): path to output folder\n",
    "        model_path (str): path to saved model\n",
    "    \"\"\"\n",
    "    print(\"initialize\")\n",
    "\n",
    "    # the runtime initialization will not allocate all memory on the device to avoid out of GPU memory\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "      try:\n",
    "        for gpu in gpus:\n",
    "          #tf.config.experimental.set_memory_growth(gpu, True)\n",
    "          tf.config.experimental.set_virtual_device_configuration(gpu,\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4000)])\n",
    "      except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "    # network resolution\n",
    "    if model_type == \"large\":\n",
    "        net_w, net_h = 384, 384\n",
    "    elif model_type == \"small\":\n",
    "        net_w, net_h = 256, 256\n",
    "    else:\n",
    "        print(f\"model_type '{model_type}' not implemented, use: --model_type large\")\n",
    "        assert False\n",
    "\n",
    "    # load network\n",
    "    graph_def = tf.compat.v1.GraphDef()\n",
    "    with tf.io.gfile.GFile(model_path, 'rb') as f:\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "    \n",
    "    model_operations = tf.compat.v1.get_default_graph().get_operations()\n",
    "    input_node = '0:0'\n",
    "    output_layer = model_operations[len(model_operations) - 1].name + ':0'\n",
    "    print(\"Last layer name: \", output_layer)\n",
    "\n",
    "    resize_image = Resize(\n",
    "                net_w,\n",
    "                net_h,\n",
    "                resize_target=None,\n",
    "                keep_aspect_ratio=False,\n",
    "                ensure_multiple_of=32,\n",
    "                resize_method=\"upper_bound\",\n",
    "                image_interpolation_method=cv2.INTER_CUBIC,\n",
    "            )\n",
    "    \n",
    "    def compose2(f1, f2):\n",
    "        return lambda x: f2(f1(x))\n",
    "\n",
    "    transform = compose2(resize_image, PrepareForNet())\n",
    "\n",
    "    # get input\n",
    "    img_names = glob.glob(os.path.join(input_path, \"*\"))\n",
    "    num_images = len(img_names)\n",
    "\n",
    "    # create output folder\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    print(\"start processing\")\n",
    "\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "      try:\n",
    "        # load images\n",
    "        for ind, img_name in enumerate(img_names):\n",
    "\n",
    "            print(\"  processing {} ({}/{})\".format(img_name, ind + 1, num_images))\n",
    "\n",
    "            # input\n",
    "            img = utils.read_image(img_name)\n",
    "            img_input = transform({\"image\": img})[\"image\"]\n",
    "\n",
    "            # compute\n",
    "            prob_tensor = sess.graph.get_tensor_by_name(output_layer)\n",
    "            prediction, = sess.run(prob_tensor, {input_node: [img_input] })\n",
    "            prediction = prediction.reshape(net_h, net_w)\n",
    "            prediction = cv2.resize(prediction, (img.shape[1], img.shape[0]), interpolation=cv2.INTER_CUBIC)\n",
    "            \n",
    "            # output\n",
    "            filename = os.path.join(\n",
    "                output_path, os.path.splitext(os.path.basename(img_name))[0]\n",
    "            )\n",
    "            utils.write_depth(filename, prediction, bits=2)\n",
    "\n",
    "      except KeyError:\n",
    "        print (\"Couldn't find input node: ' + input_node + ' or output layer: \" + output_layer + \".\")\n",
    "        exit(-1)\n",
    "\n",
    "    print(\"finished\")\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('-i', '--input_path', \n",
    "        default='input',\n",
    "        help='folder with input images'\n",
    "    )\n",
    "\n",
    "    parser.add_argument('-o', '--output_path', \n",
    "        default='output',\n",
    "        help='folder for output images'\n",
    "    )\n",
    "\n",
    "    parser.add_argument('-m', '--model_weights', \n",
    "        default='model-f6b98070.pb',\n",
    "        help='path to the trained weights of model'\n",
    "    )\n",
    "\n",
    "    parser.add_argument('-t', '--model_type', \n",
    "        default='large',\n",
    "        help='model type: large or small'\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # compute depth maps\n",
    "    prediction = run(args.input_path, args.output_path, args.model_weights, args.model_type)\n",
    "    \n",
    "    #return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize\n",
      "Last layer name:  797:0\n",
      "start processing\n",
      "  processing input/UPMC.jpg (1/1)\n"
     ]
    }
   ],
   "source": [
    "input_path  = 'input'\n",
    "output_path = 'output'\n",
    "model_path  = 'model-small.pb'\n",
    "model_type  = \"small\"\n",
    "\n",
    "prediction = run(input_path, output_path, model_path, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prediction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-286bad64f1ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prediction' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(prediction)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
