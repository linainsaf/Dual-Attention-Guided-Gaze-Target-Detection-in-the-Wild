{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load \"depth_estimation\\run.py\"\n",
    "\"\"\"Compute depth maps for images in the input folder.\n",
    "\"\"\"\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import utils\n",
    "import cv2\n",
    "import argparse\n",
    "\n",
    "from torchvision.transforms import Compose\n",
    "from midas.dpt_depth import DPTDepthModel\n",
    "from midas.midas_net import MidasNet\n",
    "from midas.midas_net_custom import MidasNet_small\n",
    "from midas.transforms import Resize, NormalizeImage, PrepareForNet\n",
    "\n",
    "\n",
    "def run(input_path, output_path, model_path, model_type=\"large\", optimize=True):\n",
    "    \"\"\"Run MonoDepthNN to compute depth maps.\n",
    "\n",
    "    Args:\n",
    "        input_path (str): path to input folder\n",
    "        output_path (str): path to output folder\n",
    "        model_path (str): path to saved model\n",
    "    \"\"\"\n",
    "    print(\"initialize\")\n",
    "\n",
    "    # select device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"device: %s\" % device)\n",
    "\n",
    "    # load network\n",
    "    if model_type == \"dpt_large\": # DPT-Large\n",
    "        model = DPTDepthModel(\n",
    "            path=model_path,\n",
    "            backbone=\"vitl16_384\",\n",
    "            non_negative=True,\n",
    "        )\n",
    "        net_w, net_h = 384, 384\n",
    "        resize_mode = \"minimal\"\n",
    "        normalization = NormalizeImage(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    elif model_type == \"dpt_hybrid\": #DPT-Hybrid\n",
    "        model = DPTDepthModel(\n",
    "            path=model_path,\n",
    "            backbone=\"vitb_rn50_384\",\n",
    "            non_negative=True,\n",
    "        )\n",
    "        net_w, net_h = 384, 384\n",
    "        resize_mode=\"minimal\"\n",
    "        normalization = NormalizeImage(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    elif model_type == \"midas_v21\":\n",
    "        model = MidasNet(model_path, non_negative=True)\n",
    "        net_w, net_h = 384, 384\n",
    "        resize_mode=\"upper_bound\"\n",
    "        normalization = NormalizeImage(\n",
    "            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    elif model_type == \"midas_v21_small\":\n",
    "        model = MidasNet_small(model_path, features=64, backbone=\"efficientnet_lite3\", exportable=True, non_negative=True, blocks={'expand': True})\n",
    "        net_w, net_h = 256, 256\n",
    "        resize_mode=\"upper_bound\"\n",
    "        normalization = NormalizeImage(\n",
    "            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    else:\n",
    "        print(f\"model_type '{model_type}' not implemented, use: --model_type large\")\n",
    "        assert False\n",
    "    \n",
    "    transform = Compose(\n",
    "        [\n",
    "            Resize(\n",
    "                net_w,\n",
    "                net_h,\n",
    "                resize_target=None,\n",
    "                keep_aspect_ratio=True,\n",
    "                ensure_multiple_of=32,\n",
    "                resize_method=resize_mode,\n",
    "                image_interpolation_method=cv2.INTER_CUBIC,\n",
    "            ),\n",
    "            normalization,\n",
    "            PrepareForNet(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    if optimize==True:\n",
    "        # rand_example = torch.rand(1, 3, net_h, net_w)\n",
    "        # model(rand_example)\n",
    "        # traced_script_module = torch.jit.trace(model, rand_example)\n",
    "        # model = traced_script_module\n",
    "    \n",
    "        if device == torch.device(\"cuda\"):\n",
    "            model = model.to(memory_format=torch.channels_last)  \n",
    "            model = model.half()\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # get input\n",
    "    img_names = glob.glob(os.path.join(input_path, \"*\"))\n",
    "    num_images = len(img_names)\n",
    "\n",
    "    # create output folder\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    print(\"start processing\")\n",
    "\n",
    "    for ind, img_name in enumerate(img_names):\n",
    "\n",
    "        print(\"  processing {} ({}/{})\".format(img_name, ind + 1, num_images))\n",
    "\n",
    "        # input\n",
    "\n",
    "        img = utils.read_image(img_name)\n",
    "        img_input = transform({\"image\": img})[\"image\"]\n",
    "\n",
    "        # compute\n",
    "        with torch.no_grad():\n",
    "            sample = torch.from_numpy(img_input).to(device).unsqueeze(0)\n",
    "            if optimize==True and device == torch.device(\"cuda\"):\n",
    "                sample = sample.to(memory_format=torch.channels_last)  \n",
    "                sample = sample.half()\n",
    "            prediction = model.forward(sample)\n",
    "            prediction = (\n",
    "                torch.nn.functional.interpolate(\n",
    "                    prediction.unsqueeze(1),\n",
    "                    size=img.shape[:2],\n",
    "                    mode=\"bicubic\",\n",
    "                    align_corners=False,\n",
    "                )\n",
    "                .squeeze()\n",
    "                .cpu()\n",
    "                .numpy()\n",
    "            )\n",
    "\n",
    "        # output\n",
    "        filename = os.path.join(\n",
    "            output_path, os.path.splitext(os.path.basename(img_name))[0]\n",
    "        )\n",
    "        utils.write_depth(filename, prediction, bits=2)\n",
    "\n",
    "    print(\"finished\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('-i', '--input_path', \n",
    "        default='input',\n",
    "        help='folder with input images'\n",
    "    )\n",
    "\n",
    "    parser.add_argument('-o', '--output_path', \n",
    "        default='output',\n",
    "        help='folder for output images'\n",
    "    )\n",
    "\n",
    "    parser.add_argument('-m', '--model_weights', \n",
    "        default=None,\n",
    "        help='path to the trained weights of model'\n",
    "    )\n",
    "\n",
    "    parser.add_argument('-t', '--model_type', \n",
    "        default='dpt_large',\n",
    "        help='model type: dpt_large, dpt_hybrid, midas_v21_large or midas_v21_small'\n",
    "    )\n",
    "\n",
    "    parser.add_argument('--optimize', dest='optimize', action='store_true')\n",
    "    parser.add_argument('--no-optimize', dest='optimize', action='store_false')\n",
    "    parser.set_defaults(optimize=True)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    default_models = {\n",
    "        \"midas_v21_small\": \"weights/midas_v21_small-70d6b9c8.pt\",\n",
    "        \"midas_v21\": \"weights/midas_v21-f6b98070.pt\",\n",
    "        \"dpt_large\": \"weights/dpt_large-midas-2f21e586.pt\",\n",
    "        \"dpt_hybrid\": \"weights/dpt_hybrid-midas-501f0c75.pt\",\n",
    "    }\n",
    "\n",
    "    if args.model_weights is None:\n",
    "        args.model_weights = default_models[args.model_type]\n",
    "\n",
    "    # set torch options\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # compute depth maps\n",
    "    run(args.input_path, args.output_path, args.model_weights, args.model_type, args.optimize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
